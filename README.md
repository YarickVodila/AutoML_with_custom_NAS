## Кастомный алгоритм поиска нейронной сети (NAS)
В данном репозитории я пытаюсь создать свой кастомный алгоритм поиска нейронной архитектуры.

### Задачи
1) Исследовать существующие решения поиска нейронной архитектуры, например AutoKeras;
2) Понять, как датасет влияет на построение нейронной сети;
3) Понять, какие дополнительные слои могут улучшить качество модели;
4) Разработать алгоритм автоматического построения модели, который включает в себя поиск архитектуры и подбор гиперпараметров таких, как количество нейронов, параметр `rate` у Dropout слоя и т.д.

### Предварительные результаты тестирования

Тестированиие проводится на датасете `Titanic`.

1) Написан тестовый алгоритм поиска нейронной архитектуры на основе модуля `optuna` (`AutiML.py`). Пример работы с данным модулем находится в файле `test_automl.ipynb`.
2) Предусмотрена проверка на переобучение с помощью `EarlyStopping`.
3) Поиск производится с использованием `TPESampler` (англ. Оценщик Парзена с древовидной структурой)

### Дальнейший план

1) Оптимизировать модуль для масштабируемости. Сделать настройку более гибкой для пользователя;
2) Добавить модуль для задачи регрессии
3) Написать свой собственный `CallBack` для гибкой настройки скорости обучения и ранней остановки при достижении определённого порогоа
4) Сделать библиотеку, чтобы можно было установить модуль через `pip`.



